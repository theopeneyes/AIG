{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LMY4_xdYyYby"
      },
      "outputs": [],
      "source": [
        "#https://machinelearningmastery.com/clean-text-machine-learning-python/\n",
        "#https://github.com/ramsrigouthamg/generate_boolean_questions_using_T5_transformer/blob/master/t5_inference.py\n",
        "#https://towardsdatascience.com/how-to-apply-transformers-to-any-length-of-text-a5601410af7f\n",
        "#https://towardsdatascience.com/generating-boolean-yes-no-questions-from-any-content-using-t5-text-to-text-transformer-model-69f2744aff44\n",
        "#https://github.com/Saadmairaj/boolean-question"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install git+https://github.com/Saadmairaj/boolean-question\n",
        "#!pip install language_tool_python\n",
        "!pip install transformers==2.5.1\n",
        "!pip install boolean_question\n",
        "!pip install datasets evaluate transformers[sentencepiece]\n",
        "!pip install sentencepiece\n",
        "!pip install docx2txt\n",
        "!pip install PyPDF2\n",
        "!pip install transformers[torch]==4.3\n",
        "!pip install torch"
      ],
      "metadata": {
        "id": "GMoFk44u6eet",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cf3ed49-3f6c-432a-8a43-15421f363a8b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==2.5.1\n",
            "  Using cached transformers-2.5.1-py3-none-any.whl (499 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (4.64.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (0.1.97)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (1.21.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (1.24.79)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (0.0.53)\n",
            "Collecting tokenizers==0.5.2\n",
            "  Using cached tokenizers-0.5.2-cp37-cp37m-manylinux1_x86_64.whl (5.6 MB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1) (3.8.0)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.5.1) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.5.1) (0.6.0)\n",
            "Requirement already satisfied: botocore<1.28.0,>=1.27.79 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.5.1) (1.27.79)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.79->boto3->transformers==2.5.1) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.79->boto3->transformers==2.5.1) (1.25.11)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.79->boto3->transformers==2.5.1) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.1) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.5.1) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.5.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.5.1) (1.1.0)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.10.3\n",
            "    Uninstalling tokenizers-0.10.3:\n",
            "      Successfully uninstalled tokenizers-0.10.3\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.3.0\n",
            "    Uninstalling transformers-4.3.0:\n",
            "      Successfully uninstalled transformers-4.3.0\n",
            "Successfully installed tokenizers-0.5.2 transformers-2.5.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: boolean_question in /usr/local/lib/python3.7/dist-packages (0.0.3)\n",
            "Requirement already satisfied: numpy==1.21.1 in /usr/local/lib/python3.7/dist-packages (from boolean_question) (1.21.1)\n",
            "Requirement already satisfied: transformers==2.5.1 in /usr/local/lib/python3.7/dist-packages (from boolean_question) (2.5.1)\n",
            "Requirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from boolean_question) (1.9.0)\n",
            "Requirement already satisfied: pandas==1.3.1 in /usr/local/lib/python3.7/dist-packages (from boolean_question) (1.3.1)\n",
            "Requirement already satisfied: torchvision==0.10.0 in /usr/local/lib/python3.7/dist-packages (from boolean_question) (0.10.0)\n",
            "Requirement already satisfied: gdown==3.13.0 in /usr/local/lib/python3.7/dist-packages (from boolean_question) (3.13.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown==3.13.0->boolean_question) (1.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown==3.13.0->boolean_question) (3.8.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown==3.13.0->boolean_question) (4.64.1)\n",
            "Requirement already satisfied: requests[socks]>=2.12.0 in /usr/local/lib/python3.7/dist-packages (from gdown==3.13.0->boolean_question) (2.23.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.1->boolean_question) (2022.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.3.1->boolean_question) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->boolean_question) (4.1.1)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0->boolean_question) (7.1.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1->boolean_question) (2022.6.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1->boolean_question) (0.0.53)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1->boolean_question) (0.1.97)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1->boolean_question) (1.24.79)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.7/dist-packages (from transformers==2.5.1->boolean_question) (0.5.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.12.0->gdown==3.13.0->boolean_question) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.12.0->gdown==3.13.0->boolean_question) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.12.0->gdown==3.13.0->boolean_question) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.12.0->gdown==3.13.0->boolean_question) (1.25.11)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.12.0->gdown==3.13.0->boolean_question) (1.7.1)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.5.1->boolean_question) (1.0.1)\n",
            "Requirement already satisfied: botocore<1.28.0,>=1.27.79 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.5.1->boolean_question) (1.27.79)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.5.1->boolean_question) (0.6.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.5.1->boolean_question) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.5.1->boolean_question) (1.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.5.1)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.7/dist-packages (0.2.2)\n",
            "Requirement already satisfied: transformers[sentencepiece] in /usr/local/lib/python3.7/dist-packages (2.5.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.9.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n",
            "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.12.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.8.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.1.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.8.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "\u001b[33mWARNING: transformers 2.5.1 does not provide the extra 'sentencepiece'\u001b[0m\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (1.24.79)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.5.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.0.53)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers[sentencepiece]) (0.1.97)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers[sentencepiece]) (0.6.0)\n",
            "Requirement already satisfied: botocore<1.28.0,>=1.27.79 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers[sentencepiece]) (1.27.79)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers[sentencepiece]) (1.0.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[sentencepiece]) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[sentencepiece]) (7.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.97)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: docx2txt in /usr/local/lib/python3.7/dist-packages (0.8)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.7/dist-packages (2.10.9)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.7/dist-packages (from PyPDF2) (4.1.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers[torch]==4.3\n",
            "  Using cached transformers-4.3.0-py3-none-any.whl (1.8 MB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers[torch]==4.3) (1.21.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers[torch]==4.3) (4.64.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Using cached tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers[torch]==4.3) (3.8.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers[torch]==4.3) (2022.6.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers[torch]==4.3) (4.12.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers[torch]==4.3) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers[torch]==4.3) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers[torch]==4.3) (0.0.53)\n",
            "Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.7/dist-packages (from transformers[torch]==4.3) (1.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0->transformers[torch]==4.3) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers[torch]==4.3) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers[torch]==4.3) (3.0.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[torch]==4.3) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[torch]==4.3) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[torch]==4.3) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers[torch]==4.3) (2022.6.15)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[torch]==4.3) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[torch]==4.3) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers[torch]==4.3) (7.1.2)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.5.2\n",
            "    Uninstalling tokenizers-0.5.2:\n",
            "      Successfully uninstalled tokenizers-0.5.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 2.5.1\n",
            "    Uninstalling transformers-2.5.1:\n",
            "      Successfully uninstalled transformers-2.5.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "boolean-question 0.0.3 requires transformers==2.5.1, but you have transformers 4.3.0 which is incompatible.\u001b[0m\n",
            "Successfully installed tokenizers-0.10.3 transformers-4.3.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MN1aaaueTndT"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "start = time.time()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6k9qnekuRe3"
      },
      "source": [
        "# **Import Libries**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HBAWrD7X2M4"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dm3WHla5uBnN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9J1H7HDD2yaG"
      },
      "source": [
        "# **Import File**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HKc-ytTsvcOs"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import requests\n",
        "request=requests.get(\"https://generate-questions.devbyopeneyes.com/api/getFileData/632a9cff94182bcda40b3122\")\n",
        "resp= request.json()\n",
        "file_path=(resp[\"data\"][\"file_path\"])\n",
        "_id=(resp[\"data\"][\"_id\"])\n",
        "number_of_question=(resp[\"data\"][\"number_of_question\"])\n",
        "file_type=(resp[\"data\"][\"file_type\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gx2LD87qGR5",
        "outputId": "99b61fda-98f5-4d30-c8a8-0dfc167fcb1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The  name of AIML developer is Roshni Hirani.\r\n",
            "Roshni Hirani is from Anand. Roshni have completed her Btech in  CE.\r\n",
            "Roshni have one sister named Pinal. Roshni stayes with her mom and dad in anand.\r\n",
            "She works in Openeyes software solutions  in vadodara.\r\n",
            "Roshni and her family are basically from kutch but have shifted to anand from past 20 years.\r\n",
            "Roshni have been born and brought up in anand it self. She have completed Her Btech from Birla vishvakarma maha vidhiyalaya.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import docx2txt\n",
        "if file_type==\"txt\":\n",
        "  import urllib.request\n",
        "  response = urllib.request.urlopen(file_path)\n",
        "  html = response.read()\n",
        "  text=html.decode('utf8')\n",
        "  print(text)\n",
        "elif file_type==\"pdf\":\n",
        "  import requests, PyPDF2\n",
        "\n",
        "  url = file_path\n",
        "  response = requests.get(url)\n",
        "  my_raw_data = response.content\n",
        "\n",
        "  with open(\"my_pdf.pdf\", 'wb') as my_data:\n",
        "      my_data.write(my_raw_data)\n",
        "\n",
        "  open_pdf_file = open(\"my_pdf.pdf\", 'rb')\n",
        "  read_pdf = PyPDF2.PdfFileReader(open_pdf_file)\n",
        "  if read_pdf.isEncrypted:\n",
        "      read_pdf.decrypt(\"\")\n",
        "      text=(read_pdf.getPage(0).extractText())\n",
        "\n",
        "  else:\n",
        "      text=(read_pdf.getPage(0).extractText())\n",
        "elif file_type==\"docx\":\n",
        "  url = file_path\n",
        "  response = requests.get(url)\n",
        "  my_raw_data = response.content\n",
        "\n",
        "  with open(\"my_doc.txt\", \"wb\") as text_file:\n",
        "    text_file.write(my_raw_data)\n",
        "\n",
        "  open_docx_file = open(\"my_doc.txt\", 'rb')\n",
        "\n",
        "  text = docx2txt.process(open_docx_file)\n",
        "  print(text)\n",
        "elif file_type==\"doc\":\n",
        "  None\n",
        "else:\n",
        "  print(\"Invalid File Type\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62E3GARRupcv"
      },
      "source": [
        "**Download Library**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPpCc-jNuLhT",
        "outputId": "84e897ad-9aa7-4994-94b2-511f27ae6499"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Mmv24DOvvGe"
      },
      "source": [
        "# **Data Cleaing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SK6G-67ju4Yc"
      },
      "source": [
        "**Step 1 : Split text file into sentences**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qm7IA8mNZUK_",
        "outputId": "ba6096c1-6db0-4994-9cf0-8bea253ff03f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The  name of AIML developer is Roshni Hirani.', 'Roshni Hirani is from Anand.', 'Roshni have completed her Btech in  CE.', 'Roshni have one sister named Pinal.', 'Roshni stayes with her mom and dad in anand.', 'She works in Openeyes software solutions  in vadodara.', 'Roshni and her family are basically from kutch but have shifted to anand from past 20 years.', 'Roshni have been born and brought up in anand it self.', 'She have completed Her Btech from Birla vishvakarma maha vidhiyalaya.']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from nltk import sent_tokenize\n",
        "sentences = sent_tokenize(text)\n",
        "print(sentences)\n",
        "text_to_sentence= np.array(sentences)\n",
        "len(text_to_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctTXaYFmu-YX"
      },
      "source": [
        "**Step 2 : Split sentences into words by white space**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Tn-sd-aA0tSM"
      },
      "outputs": [],
      "source": [
        "sentence_to_words=[]\n",
        "for i in text_to_sentence[0:]:\n",
        "    sentence_to_words.extend(i.split()) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuVsImHtwCAO"
      },
      "source": [
        "**Step 3 : Remove Unwanted Words** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0xJ3L59VoSg8"
      },
      "outputs": [],
      "source": [
        "tokens = [ w for w in sentence_to_words if w[0]!='[' and w[-1]!= ']' ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-wZDpe3vHi9"
      },
      "source": [
        "**Step 4 : Remove punctuation from each word(except full stop(.))**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "tC1FqZYi1Szk"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "remove = string.punctuation\n",
        "import re \n",
        "remove = remove.replace(\".\", \"\")\n",
        "pattern = r\"[{}]\".format(re.escape(remove))\n",
        "table = str.maketrans('', '', pattern)\n",
        "stripped = [w.translate(table) for w in tokens]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqcqg2T1vNrP"
      },
      "source": [
        "**Step 5 : Join Sentence**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "PPp-SveV1cVV",
        "outputId": "14b7cf7f-795a-445b-e3b0-6f77be9b2745"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The name of AIML developer is Roshni Hirani. Roshni Hirani is from Anand. Roshni have completed her Btech in CE. Roshni have one sister named Pinal. Roshni stayes with her mom and dad in anand. She works in Openeyes software solutions in vadodara. Roshni and her family are basically from kutch but have shifted to anand from past 20 years. Roshni have been born and brought up in anand it self. She have completed Her Btech from Birla vishvakarma maha vidhiyalaya.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "words_to_sentense=' '.join(stripped)\n",
        "words_to_sentense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "GqxkXbp8p7Vf"
      },
      "outputs": [],
      "source": [
        "sentences_new = sent_tokenize(words_to_sentense)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEQeUZWCGpYX"
      },
      "source": [
        "# **Take Input From User Locally**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "LpPDISBI3POk"
      },
      "outputs": [],
      "source": [
        "generate_ques=int(number_of_question)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrA5NUgmzkVm"
      },
      "source": [
        "## **Generate_boolean_questions_using_T5_transformer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXzvt_il1HSM",
        "outputId": "3165c17e-af66-45cd-a1cc-5c5d52abc070"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
            "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
            "  return torch.floor_divide(self, other)\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import torch\n",
        "from transformers import T5ForConditionalGeneration,T5Tokenizer\n",
        "\n",
        "def set_seed(seed):\n",
        "  torch.manual_seed(seed)\n",
        "  if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)    \n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "model = T5ForConditionalGeneration.from_pretrained('ramsrigouthamg/t5_boolean_questions')\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "def greedy_decoding (inp_ids,attn_mask):\n",
        "  greedy_output = model.generate(input_ids=inp_ids, attention_mask=attn_mask, max_length=256)\n",
        "  Question =  tokenizer.decode(greedy_output[0], skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
        "  return Question.strip().capitalize()\n",
        "\n",
        "\n",
        "def beam_search_decoding (inp_ids,attn_mask):\n",
        "  beam_output = model.generate(input_ids=inp_ids,\n",
        "                                 attention_mask=attn_mask,\n",
        "                                 max_length=256,\n",
        "                               num_beams=2,\n",
        "                               num_return_sequences=2,\n",
        "                               no_repeat_ngram_size=2,\n",
        "                               early_stopping=True\n",
        "                               )\n",
        "  Questions = [tokenizer.decode(out, skip_special_tokens=True, clean_up_tokenization_spaces=True) for out in\n",
        "               beam_output]\n",
        "  return [Question.strip().capitalize() for Question in Questions]\n",
        "\n",
        "\n",
        "def topkp_decoding (inp_ids,attn_mask):\n",
        "  topkp_output = model.generate(input_ids=inp_ids,\n",
        "                                 attention_mask=attn_mask,\n",
        "                                 max_length=256,\n",
        "                               do_sample=True,\n",
        "                               top_k=40,\n",
        "                               top_p=0.80,\n",
        "                               num_return_sequences=1,\n",
        "                                no_repeat_ngram_size=2,\n",
        "                                early_stopping=True\n",
        "                               )\n",
        "  Questions = [tokenizer.decode(out, skip_special_tokens=True,clean_up_tokenization_spaces=True) for out in topkp_output]\n",
        "  return [Question.strip().capitalize() for Question in Questions]\n",
        "\n",
        "max_len = 512\n",
        "context_list=[]\n",
        "question_list=[]\n",
        "\n",
        "for i in sentences_new: \n",
        "  encoding = tokenizer.encode_plus(i, return_tensors=\"pt\", add_special_tokens=True,max_length=max_len, truncation=True,padding=True)\n",
        "  input_ids, attention_masks = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n",
        "  question_append = beam_search_decoding(input_ids,attention_masks)\n",
        "  context_list.append(i)\n",
        "  context_list.append(i)\n",
        "  for out in question_append:\n",
        "    question_list.append(out)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGEZSJPdGu7-"
      },
      "source": [
        "## **Remove Duplicates**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhglZCC98KMg",
        "outputId": "214370c1-6593-49f7-cfa4-43b9c470f00d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None,\n",
              " None]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "new_questions = question_list\n",
        "new_questions4 = []\n",
        "\n",
        "[new_questions4.append(x) for x in new_questions if x not in new_questions4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBCFAKi68nk5"
      },
      "source": [
        "# Predicting answers Yes/No"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "VUaNyZxUcxFq"
      },
      "outputs": [],
      "source": [
        "from transformers import (\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wn3-Ov6HcxDM",
        "outputId": "f31e7ec0-cd58-49f2-9cd3-2460e7992b34"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\"shahrukhx01/roberta-base-boolq\")\n",
        "model.to(device) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ULbM3GiBcwzU"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"shahrukhx01/roberta-base-boolq\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "rizJWoG3dMe1"
      },
      "outputs": [],
      "source": [
        "class rx:\n",
        " def predict(question, passage):\n",
        "  sequence = tokenizer.encode_plus(question, passage, return_tensors=\"pt\")['input_ids']\n",
        "  \n",
        "  logits = model(sequence)[0]\n",
        "  probabilities = torch.softmax(logits, dim=1).detach().cpu().tolist()[0]\n",
        "  proba_yes = round(probabilities[1], 2)\n",
        "  proba_no = round(probabilities[0], 2)\n",
        "  if proba_yes>0.8:\n",
        "    return True\n",
        "  else:\n",
        "    return False  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwN7EFNjfSMT",
        "outputId": "39b58e4e-e72a-435e-bc0b-a8013b3437ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[True, False, True, True, True, True, True, True, True, True, True, True, True, False, False, False, True, True]\n"
          ]
        }
      ],
      "source": [
        "answers=[]\n",
        "\n",
        "for i, j in zip(question_list, context_list ):\n",
        "   answers.append(rx.predict(i, j))\n",
        "print(answers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "BERknw2n43lV"
      },
      "outputs": [],
      "source": [
        "questions=str(new_questions4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eof2GQXgGy5_"
      },
      "source": [
        "## **Grammar Correction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "lqDzF2I5bpRb"
      },
      "outputs": [],
      "source": [
        "Ques_Ans = []\n",
        "\n",
        "for i in new_questions4:\n",
        "  Ques_Ans.append({\"question\":i})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nf2GEqq8VcB",
        "outputId": "3a4fc459-d677-44b1-c4ed-943b4c9e0f7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'question': 'Is roshni hirani a developer of aiml?'}\n",
            "{'question': 'Is roshni hirani the same as rohiti hirani?'}\n",
            "{'question': 'Is roshni from anand a native of india?'}\n",
            "{'question': 'Is roshni from anand from india?'}\n",
            "{'question': 'Has roshni completed her btech?'}\n",
            "{'question': 'Has roshni completed her btech in chemistry?'}\n",
            "{'question': 'Is pinal and roshni the same person?'}\n",
            "{'question': \"Is pinal and roshni's sister a girl?\"}\n",
            "{'question': 'Does roshni stay with her mom and dad?'}\n",
            "{'question': 'Do roshni and her dad live in the same place?'}\n",
            "{'question': 'Is there a software company in vadodara?'}\n",
            "{'question': 'Is there a woman in openeyes who works in vadodar?'}\n",
            "{'question': 'Is roshni and her family from kutch?'}\n",
            "{'question': 'Is roshni from kutch a kashmiri?'}\n",
            "{'question': 'Has roshni been born in india?'}\n",
            "{'question': 'Is roshni a native of india?'}\n",
            "{'question': 'Has a student completed btech from birla vishvakarma?'}\n",
            "{'question': 'Has a student completed her btech?'}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "scoring = []\n",
        "for i in Ques_Ans:\n",
        "  print(i)\n",
        "  #e=list(i.keys())[2]\n",
        "  e=i.get(\"question\")\n",
        "  scoring.append(e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "RcAP63mz8fmy"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "question_answerer = pipeline(\"question-answering\")\n",
        "context = words_to_sentense\n",
        "de=[]\n",
        "for i in new_questions4:\n",
        "  d = question_answerer(question=i, context=context)\n",
        "  e=d.get(\"score\")\n",
        "  e_updated=1-float(e)\n",
        "  accuracy_score=\"%.2f\" % round(e_updated*100, 2)\n",
        "  de.append(accuracy_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGCgTHnCiCAp"
      },
      "source": [
        "##Get Context, rank and answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "cfE0zcLd8hyK"
      },
      "outputs": [],
      "source": [
        "for option_index, option in enumerate(Ques_Ans):\n",
        "    option[\"context\"] = context_list[option_index]\n",
        "    option[\"rank\"] = de[option_index]\n",
        "    option[\"answer\"] = answers[option_index]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_generated_questions = sorted(Ques_Ans, key=lambda i: i['rank'],reverse=True)"
      ],
      "metadata": {
        "id": "ya1JHPzH9TkV"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "EVHMVqgWTwmi"
      },
      "outputs": [],
      "source": [
        "end = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "EPzsYSSvT2UW"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "dt1 = datetime.fromtimestamp(start)\n",
        "dt2 = datetime.fromtimestamp(end)\n",
        "total_time = dt2 - dt1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxBDEh-PG6yk"
      },
      "source": [
        "## **Final Output , User Validation & Post Generated Questions**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if generate_ques > len(final_generated_questions) or generate_ques == 0: \n",
        "  print(\"please give value between 1 to {}\".format(len(final_generated_questions)))\n",
        "else:\n",
        "    middle_index = generate_ques\n",
        "    user_required_questions = final_generated_questions[:middle_index]\n",
        "    other_questions = final_generated_questions[middle_index:]\n",
        "\n",
        "    \n",
        "    for question_index, question in enumerate(user_required_questions):\n",
        "      question[\"question_id\"]= question_index +1\n",
        "\n",
        "    for question_index, question in enumerate(other_questions):\n",
        "      question[\"question_id\"]= question_index +1"
      ],
      "metadata": {
        "id": "_lu32jH-89hP"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "YaA_LlT-3mF4"
      },
      "outputs": [],
      "source": [
        "url=\"https://generate-questions.devbyopeneyes.com/api/GenerateQuestions\" \n",
        "headers = {'Content-Type':'application/json','Accept':'application/json'}\n",
        "post_array ={\"id\" : _id,\n",
        "       \"questions\" : user_required_questions,\n",
        "       \"other_questions\" : other_questions,\n",
        "       \"upload_process_time\": str(total_time)\n",
        "  }\n",
        "status = requests.post(url,headers=headers,data=json.dumps(post_array))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
